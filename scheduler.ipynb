{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use file name generate entire schedule\n",
    "\n",
    "import pandas as pd\n",
    "from calculation import generate_sch_from_list\n",
    "TPL_currentSeason=r'C:\\Users\\harsh\\Downloads\\TPL_Doubles.xlsx'\n",
    "df=pd.read_excel(TPL_currentSeason, engine ='openpyxl',sheet_name ='PointTable',keep_default_na=False)\n",
    "\n",
    "\n",
    "schedule_list=[]\n",
    "for d in df['Division'].unique():\n",
    "     tempDiv=df.loc[df['Division']==d]\n",
    "     for group in tempDiv['Group'].unique():\n",
    "          lst=tempDiv.loc[tempDiv['Group']==group]['Team'].to_list() #for singles Player, doubles Team\n",
    "          schedule_list.extend(generate_sch_from_list(lst))\n",
    "\n",
    "pd.DataFrame(schedule_list).to_html('temp.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pankaj & Akshay\n",
      " Harpreet & David Clerc \n",
      " Kedar & Ramana\n",
      " Eric Salgado & Aaron\n",
      " Trent & Diego Burgi\n",
      " Ganesh & Keith\n",
      " Chavel & Randy\n",
      " Alok & Arun\n",
      " Madhu & Rajesh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{5.0:                        Team  Points  %games  Matches\n",
       " 0           Pankaj & Akshay       0       0        0\n",
       " 1   Harpreet & David Clerc        0       0        0\n",
       " 2            Kedar & Ramana       0       0        0\n",
       " 3      Eric Salgado & Aaron       0       0        0\n",
       " 4       Trent & Diego Burgi       0       0        0\n",
       " 5            Ganesh & Keith       0       0        0\n",
       " 6            Chavel & Randy       0       0        0\n",
       " 7               Alok & Arun       0       0        0\n",
       " 8            Madhu & Rajesh       0       0        0,\n",
       " 4.0:                                Team  Points  %games  Matches\n",
       " 9                Prasanna & Richard       0       0        0\n",
       " 10                     David/Thomas       0       0        0\n",
       " 11              Adil /  Aariz Syed        0       0        0\n",
       " 12                     Anjum/Suhail       0       0        0\n",
       " 13   Srinivas Balusu/ Sriram Venkat       0       0        0\n",
       " 14                    Raam/Satheesh       0       0        0\n",
       " 15                   Lazer/Prasanna       0       0        0\n",
       " 16            Arul/Senthil Sainath        0       0        0\n",
       " 17                   Raj/ Raj’s Son       0       0        0\n",
       " 18                   Harshil/ Ayan        0       0        0\n",
       " 19                  ⁠Logan/ Darshan       0       0        0\n",
       " 20                   ⁠Gunjan/Mahesh       0       0        0\n",
       " 21        ⁠Narayan/Karthik Ganesan        0       0        0\n",
       " 22        ⁠Leslie/Senthil Kathirvel       0       0        0,\n",
       " 4.5:                             Team  Points  %games  Matches\n",
       " 23         Chengwei & Hanson Jin       0       0        0\n",
       " 24                  Juan & Rohit       0       0        0\n",
       " 25                   Anil & Dale       0       0        0\n",
       " 26              Nihar & Vastalya       0       0        0\n",
       " 27                Gunjan & Pinku       0       0        0\n",
       " 28                Amit & Chandra       0       0        0\n",
       " 29       Dave Kusko & John Kusko       0       0        0\n",
       " 30                   Sam & Amol        0       0        0\n",
       " 31       Jesus & Francisco Diaz        0       0        0\n",
       " 32             Surya & Srikanth        0       0        0\n",
       " 33              Praveen & Arvind       0       0        0\n",
       " 34                Sunil & Sunny        0       0        0\n",
       " 35             ⁠Anand & Q Javed        0       0        0\n",
       " 36   ⁠Ravinder & Rohit Mahapatra       0       0        0}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "TPL_currentSeason=r'C:\\Users\\harsh\\Repo\\TPL\\TPL\\TPL_Doubles.xlsx'\n",
    "df_PT=pd.read_excel(TPL_currentSeason, engine ='openpyxl',sheet_name ='PointTable',keep_default_na=False)\n",
    "\n",
    "unique_divs=df_PT['Division'].unique()\n",
    "div_dict=dict.fromkeys(unique_divs)\n",
    "\n",
    "\n",
    "for div in unique_divs:\n",
    "    div_dict[div]=df_PT.loc[df_PT['Division']==div][['Team','Points','%games','Matches']]\n",
    "\n",
    "for index,row in div_dict[5.0].iterrows():\n",
    "    print(row['Team'])\n",
    "\n",
    "div_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REPORINTG ISHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filename=r'C:\\Users\\harsh\\Downloads\\Copy of Volunteer reporting.xlsx'\n",
    "df=pd.read_excel(filename, engine ='openpyxl',sheet_name ='Sheet1',keep_default_na=False)\n",
    "\n",
    "#remove top 2 rows\n",
    "df=df.iloc[2:,:]\n",
    "\n",
    "#make first row as header\n",
    "df.columns=df.iloc[0]\n",
    "df=df.iloc[1:,:]\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "#keep only required columns\n",
    "df=df[['Task Name','Status','Team-CN-VOL (labels)','Volunteer Type-CN-VOL (labels)']]\n",
    "#rename columns\n",
    "df.columns=['Volunteer Name','Status','Team','Volunteer Type']\n",
    "\n",
    "\n",
    "\n",
    "#remove row that contains value Team-CN-VOL (labels) in Team column\n",
    "df=df[df['Team']!='Team-CN-VOL (labels)']\n",
    "df.to_html('temp.html')\n",
    "\n",
    "#replace empty string Team as 'Not Assigned'\n",
    "df['Team']=df['Team'].replace('', 'Not Assigned')\n",
    "\n",
    "\n",
    "#remove rows with emtpr string in Volunteer Name\n",
    "df=df[df['Volunteer Name']!='']\n",
    "\n",
    "#split a row to multiple rows if the Team column has multiple values seperated by comma\n",
    "df=df.assign(Team=df['Team'].str.split(',')).explode('Team')\n",
    "\n",
    "\n",
    "#write back to excel with filename as Volunteer data for reporting.xlsx with no index column\n",
    "df.to_excel(r'C:\\Users\\harsh\\Downloads\\Volunteer data for reporting.xlsx',index=False)\n",
    "\n",
    "\n",
    "df.to_html('temp.html')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "filename=r\"C:\\Users\\harsh\\Downloads\\Vendor List - Amila.xlsx\"\n",
    "#read file no header and no index column\n",
    "df=pd.read_excel(filename, engine ='openpyxl',sheet_name ='Revised',keep_default_na=False,header=None)\n",
    "#replace first columns a name\n",
    "df.columns=['vendor name']\n",
    "\n",
    "# # Ensure index values are strings\n",
    "# df.index = df.index.astype(str)\n",
    "\n",
    "# Remove all non-alphanumeric characters (anything except letters and digits) from vendor name\n",
    "non_special_chars = re.compile(r'[^a-zA-Z0-9]')\n",
    "df['non_special_chars'] = [re.sub(non_special_chars, '', vendor).lower() for vendor in df['vendor name']]\n",
    "df\n",
    "\n",
    "# for vendor in df['vendor name']:\n",
    "#     print(re.sub(r'[^a-zA-Z0-9]', '', vendor).lower())\n",
    "\n",
    "\n",
    "\n",
    "#get first word of the first column\n",
    "df['First Word']=df['vendor name'].str.split().str[0]\n",
    "# unique_first_word=df['First Word'].unique()\n",
    "#remove special characters from first word\n",
    "non_special_chars = re.compile(r'[^a-zA-Z0-9]')\n",
    "non_special_first_word = [re.sub(non_special_chars, '', word) for word in df['First Word']]\n",
    "non_special_first_word\n",
    "#get unique non special first word\n",
    "unique_non_special_first_word=set(non_special_first_word)\n",
    "unique_non_special_first_word\n",
    "# new_df=pd.DataFrame(unique_first_word,columns=['First Word'])\n",
    "# new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict of unique non special first word as keys\n",
    "Alias_dict=dict.fromkeys(unique_non_special_first_word)\n",
    "\n",
    "for word in unique_non_special_first_word:\n",
    "    matches = df[df['non_special_chars'].str.contains(word, case=False, na=False)]\n",
    "    Alias_dict[word]=matches['vendor name'].to_list()\n",
    "\n",
    "Alias_dict\n",
    "#write the dict to excel in a new sheet as a sinclgle column\n",
    "Alias_df=pd.DataFrame(list(Alias_dict.items()), columns=['Vendor Match', 'Alias'])\n",
    "\n",
    "#sort df by Vendor Match\n",
    "Alias_df=Alias_df.sort_values(by='Vendor Match')\n",
    "#write the df to excel in a new sheet \n",
    "Alias_df.to_excel(r'C:\\Users\\harsh\\Downloads\\Vendor-Alias.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': ['31W Insulation', '31-W Insulation Co., Inc.']}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vendor_alias={}\n",
    "matches=df[df['non_special_chars'].str.contains('31W',case=False)]\n",
    "vendor_alias['test']=matches['vendor name'].to_list()\n",
    "vendor_alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Vendor Name  \\\n",
      "0                                 A & A Printing, INC.   \n",
      "1                                     A Plus Fasteners   \n",
      "2                                    A&A Printing, Inc   \n",
      "3                                          A+ Painting   \n",
      "4                                         AAA Painting   \n",
      "..                                                 ...   \n",
      "180                                 Vick Surveying LLC   \n",
      "181                                Vick Surveying, LLC   \n",
      "182                         Volunteer Concrete Pumping   \n",
      "183              Zoroastrian Association of California   \n",
      "184  Zoroastrian Association of California, Invoice...   \n",
      "\n",
      "                                        Matching Names  \n",
      "0                                  [A&A Printing, Inc]  \n",
      "1        [A-Plus Fasteners LLC, A-Plus Fasteners, LLC]  \n",
      "2                               [A & A Printing, INC.]  \n",
      "3                                       [AAA Painting]  \n",
      "4                                        [A+ Painting]  \n",
      "..                                                 ...  \n",
      "180                              [Vick Surveying, LLC]  \n",
      "181                               [Vick Surveying LLC]  \n",
      "182  [Valley Concrete Pumping, Xtreme Concrete Pump...  \n",
      "183  [Zoroastrian Association of California, Invoic...  \n",
      "184            [Zoroastrian Association of California]  \n",
      "\n",
      "[185 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import pandas as pd\n",
    "import re\n",
    "filename=r\"C:\\Users\\harsh\\Downloads\\Vendor List - Amila.xlsx\"\n",
    "#read file no header and no index column\n",
    "df=pd.read_excel(filename, engine ='openpyxl',sheet_name ='Revised',keep_default_na=False,header=None)\n",
    "#replace first columns a name\n",
    "df.columns=['vendor_names']\n",
    "df\n",
    "\n",
    "\n",
    "# Function to calculate string similarity between two strings\n",
    "def string_similarity(str1, str2):\n",
    "    return SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "# Threshold for considering names as a match\n",
    "threshold = 0.8\n",
    "\n",
    "# Step 1: Initialize an empty dictionary to store the matches\n",
    "matches = {}\n",
    "\n",
    "# Step 2: Compare each name in the DataFrame column with all other names\n",
    "for i, name1 in enumerate(df['vendor_names']):\n",
    "    for j, name2 in enumerate(df['vendor_names']):\n",
    "        if i != j:  # Avoid comparing the same name with itself\n",
    "            similarity_score = string_similarity(name1, name2)\n",
    "            if similarity_score >= threshold:\n",
    "                if name1 not in matches:\n",
    "                    matches[name1] = [name2]\n",
    "                else:\n",
    "                    matches[name1].append(name2)\n",
    "\n",
    "# Step 3: Convert the matches dictionary into a DataFrame for better visualization\n",
    "matches_df = pd.DataFrame({\n",
    "    'Vendor Name': matches.keys(),\n",
    "    'Matching Names': matches.values()\n",
    "})\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(matches_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import pandas as pd\n",
    "import re\n",
    "filename=r\"C:\\Users\\harsh\\Downloads\\Vendor List - Amila.xlsx\"\n",
    "#read file no header and no index column\n",
    "df=pd.read_excel(filename, engine ='openpyxl',sheet_name ='Revised',keep_default_na=False,header=None)\n",
    "#replace first columns a name\n",
    "df.columns=['vendor_names']\n",
    "df\n",
    "\n",
    "# Function to calculate string similarity between two strings\n",
    "def string_similarity(str1, str2):\n",
    "    return SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "# Set thresholds\n",
    "strong_threshold = 0.8  # for strong matches\n",
    "weak_threshold = 0.6    # for weak matches\n",
    "\n",
    "# Initialize dictionaries to store matches\n",
    "strong_matches = {}\n",
    "weak_matches = {}\n",
    "\n",
    "# Compare each name in the DataFrame column with all other names\n",
    "for i, name1 in enumerate(df['vendor_names']):\n",
    "    for j, name2 in enumerate(df['vendor_names']):\n",
    "        if i != j:  # Avoid comparing the same name with itself\n",
    "            similarity_score = string_similarity(name1, name2)\n",
    "            \n",
    "            # Strong match condition\n",
    "            if similarity_score >= strong_threshold:\n",
    "                if name1 not in strong_matches:\n",
    "                    strong_matches[name1] = [name2]\n",
    "                else:\n",
    "                    strong_matches[name1].append(name2)\n",
    "            \n",
    "            # Weak match condition\n",
    "            elif weak_threshold <= similarity_score < strong_threshold:\n",
    "                if name1 not in weak_matches:\n",
    "                    weak_matches[name1] = [name2]\n",
    "                else:\n",
    "                    weak_matches[name1].append(name2)\n",
    "\n",
    "# Prepare a DataFrame for strong matches\n",
    "strong_matches_df = pd.DataFrame({\n",
    "    'vendor_names': strong_matches.keys(),\n",
    "    'Strong Matching Names': strong_matches.values()\n",
    "})\n",
    "\n",
    "# Prepare a DataFrame for weak matches\n",
    "weak_matches_df = pd.DataFrame({\n",
    "    'vendor_names': weak_matches.keys(),\n",
    "    'Weak Matching Names': weak_matches.values()\n",
    "})\n",
    "\n",
    "# Merge strong and weak matches with the original DataFrame\n",
    "all_vendors_df = df.merge(strong_matches_df, on='vendor_names', how='left').merge(\n",
    "    weak_matches_df, on='vendor_names', how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values with \"No Matches\"\n",
    "all_vendors_df.fillna(\"No Matches\", inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(all_vendors_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vendors_df.to_excel(r'C:\\Users\\harsh\\Downloads\\Vendor-Alias-2.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fuzzywuzzy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfuzzywuzzy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fuzz\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfuzzywuzzy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process\n\u001b[0;32m      7\u001b[0m filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mharsh\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVendor List - Amila.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fuzzywuzzy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "filename=r\"C:\\Users\\harsh\\Downloads\\Vendor List - Amila.xlsx\"\n",
    "#read file no header and no index column\n",
    "df=pd.read_excel(filename, engine ='openpyxl',sheet_name ='Revised',keep_default_na=False,header=None)\n",
    "#replace first columns a name\n",
    "df.columns=['vendor_names']\n",
    "df\n",
    "\n",
    "\n",
    "# Function to find matches using fuzzywuzzy\n",
    "def find_matches(vendor_names):\n",
    "    strong_matches = {}\n",
    "    weak_matches = {}\n",
    "    \n",
    "    for name in vendor_names:\n",
    "        # Find matches with a score threshold\n",
    "        strong_matches[name], _ = process.extract(name, vendor_names, scorer=fuzz.token_sort_ratio, limit=None)\n",
    "        weak_matches[name], _ = process.extract(name, vendor_names, scorer=fuzz.partial_ratio, limit=None)\n",
    "        \n",
    "        # Filter strong matches\n",
    "        strong_matches[name] = [match for match in strong_matches[name] if fuzz.token_sort_ratio(name, match) >= 80 and match != name]\n",
    "        \n",
    "        # Filter weak matches\n",
    "        weak_matches[name] = [match for match in weak_matches[name] if 60 <= fuzz.partial_ratio(name, match) < 80 and match != name]\n",
    "\n",
    "    return strong_matches, weak_matches\n",
    "\n",
    "# Find matches\n",
    "strong_matches, weak_matches = find_matches(df['vendor_names'])\n",
    "\n",
    "# Prepare DataFrame for strong matches\n",
    "strong_matches_df = pd.DataFrame({\n",
    "    'vendor_names': strong_matches.keys(),\n",
    "    'Strong Matching Names': [', '.join(value) for value in strong_matches.values()]\n",
    "})\n",
    "\n",
    "# Prepare DataFrame for weak matches\n",
    "weak_matches_df = pd.DataFrame({\n",
    "    'vendor_names': weak_matches.keys(),\n",
    "    'Weak Matching Names': [', '.join(value) for value in weak_matches.values()]\n",
    "})\n",
    "\n",
    "# Merge strong and weak matches with the original DataFrame\n",
    "all_vendors_df = df.merge(strong_matches_df, on='vendor_names', how='left').merge(\n",
    "    weak_matches_df, on='vendor_names', how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values with \"No Matches\"\n",
    "all_vendors_df.fillna(\"No Matches\", inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(all_vendors_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
